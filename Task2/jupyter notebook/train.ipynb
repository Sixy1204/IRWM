{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dataset import Data\n",
    "from bprModel import BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():    \n",
    "    df = pd.read_csv('train.csv')\n",
    "    user_items = {}\n",
    "    itemId_max=[]\n",
    "    for i,row in df.iterrows():\n",
    "        user = int(row[0])\n",
    "        user_items[user] = [int(x) for x in row[1].split()]\n",
    "        itemId_max.append(max(user_items[user]))\n",
    "    num_users = max(user_items.keys())+1\n",
    "    num_items = max(itemId_max)+1\n",
    "    return num_users, num_items, user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, optimizer, epochs, batch_size, device):\n",
    "    trainLoss = []\n",
    "    valLoss = []\n",
    "    for epoch in range(epochs+1):\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  \n",
    "            else:\n",
    "                model.train(False)  \n",
    "            \n",
    "            model.to(device)\n",
    "            data_loaders[phase].dataset.get_neg()\n",
    "            for batch, (batch_u, batch_i, batch_j) in enumerate(data_loaders[phase]):\n",
    "                \n",
    "                batch_u = batch_u.to(device)\n",
    "                batch_i = batch_i.to(device)\n",
    "                batch_j = batch_j.to(device)\n",
    "            \n",
    "                loss = model(batch_u, batch_i, batch_j)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_loss.append(loss.data)\n",
    "                else:\n",
    "                    val_loss.append(loss.data)\n",
    "                    \n",
    "        avg_train_batch_loss = torch.mean(torch.FloatTensor(train_loss))/batch_size\n",
    "        avg_val_batch_loss = torch.mean(torch.FloatTensor(val_loss))/batch_size\n",
    "        \n",
    "        trainLoss.append(avg_train_batch_loss)\n",
    "        valLoss.append(avg_val_batch_loss)\n",
    "        \n",
    "        print(f\"Epoch : {epoch} | Avg. train batch loss = {avg_train_batch_loss:.4f} | Avg. val batch loss = {avg_val_batch_loss:.4f}\\n\")\n",
    "    \n",
    "    #return trainLoss, valLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_size, item_size,user_items = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3000\n",
    "epochs = 55\n",
    "embedding_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = Data(user_size, item_size, user_items)\n",
    "validation_split = 0.1\n",
    "shuffle_dataset = True\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(233)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "data_loaders = {\"train\": train_loader, \"val\": validation_loader}\n",
    "data_lengths = {\"train\": len(train_indices), \"val\": len(val_indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BPR(user_size, item_size, embedding_size, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | Avg. train batch loss = 0.6866 | Avg. val batch loss = 0.6189\n",
      "\n",
      "Epoch : 1 | Avg. train batch loss = 0.5067 | Avg. val batch loss = 0.3542\n",
      "\n",
      "Epoch : 2 | Avg. train batch loss = 0.3383 | Avg. val batch loss = 0.2985\n",
      "\n",
      "Epoch : 3 | Avg. train batch loss = 0.3025 | Avg. val batch loss = 0.2786\n",
      "\n",
      "Epoch : 4 | Avg. train batch loss = 0.2786 | Avg. val batch loss = 0.2607\n",
      "\n",
      "Epoch : 5 | Avg. train batch loss = 0.2585 | Avg. val batch loss = 0.2418\n",
      "\n",
      "Epoch : 6 | Avg. train batch loss = 0.2420 | Avg. val batch loss = 0.2340\n",
      "\n",
      "Epoch : 7 | Avg. train batch loss = 0.2270 | Avg. val batch loss = 0.2258\n",
      "\n",
      "Epoch : 8 | Avg. train batch loss = 0.2164 | Avg. val batch loss = 0.2174\n",
      "\n",
      "Epoch : 9 | Avg. train batch loss = 0.2068 | Avg. val batch loss = 0.2084\n",
      "\n",
      "Epoch : 10 | Avg. train batch loss = 0.1995 | Avg. val batch loss = 0.2064\n",
      "\n",
      "Epoch : 11 | Avg. train batch loss = 0.1933 | Avg. val batch loss = 0.1960\n",
      "\n",
      "Epoch : 12 | Avg. train batch loss = 0.1851 | Avg. val batch loss = 0.1921\n",
      "\n",
      "Epoch : 13 | Avg. train batch loss = 0.1768 | Avg. val batch loss = 0.1896\n",
      "\n",
      "Epoch : 14 | Avg. train batch loss = 0.1699 | Avg. val batch loss = 0.1875\n",
      "\n",
      "Epoch : 15 | Avg. train batch loss = 0.1663 | Avg. val batch loss = 0.1866\n",
      "\n",
      "Epoch : 16 | Avg. train batch loss = 0.1620 | Avg. val batch loss = 0.1767\n",
      "\n",
      "Epoch : 17 | Avg. train batch loss = 0.1568 | Avg. val batch loss = 0.1784\n",
      "\n",
      "Epoch : 18 | Avg. train batch loss = 0.1523 | Avg. val batch loss = 0.1755\n",
      "\n",
      "Epoch : 19 | Avg. train batch loss = 0.1474 | Avg. val batch loss = 0.1732\n",
      "\n",
      "Epoch : 20 | Avg. train batch loss = 0.1425 | Avg. val batch loss = 0.1709\n",
      "\n",
      "Epoch : 21 | Avg. train batch loss = 0.1402 | Avg. val batch loss = 0.1670\n",
      "\n",
      "Epoch : 22 | Avg. train batch loss = 0.1367 | Avg. val batch loss = 0.1638\n",
      "\n",
      "Epoch : 23 | Avg. train batch loss = 0.1328 | Avg. val batch loss = 0.1675\n",
      "\n",
      "Epoch : 24 | Avg. train batch loss = 0.1305 | Avg. val batch loss = 0.1667\n",
      "\n",
      "Epoch : 25 | Avg. train batch loss = 0.1264 | Avg. val batch loss = 0.1626\n",
      "\n",
      "Epoch : 26 | Avg. train batch loss = 0.1232 | Avg. val batch loss = 0.1622\n",
      "\n",
      "Epoch : 27 | Avg. train batch loss = 0.1209 | Avg. val batch loss = 0.1588\n",
      "\n",
      "Epoch : 28 | Avg. train batch loss = 0.1178 | Avg. val batch loss = 0.1619\n",
      "\n",
      "Epoch : 29 | Avg. train batch loss = 0.1141 | Avg. val batch loss = 0.1550\n",
      "\n",
      "Epoch : 30 | Avg. train batch loss = 0.1122 | Avg. val batch loss = 0.1587\n",
      "\n",
      "Epoch : 31 | Avg. train batch loss = 0.1103 | Avg. val batch loss = 0.1567\n",
      "\n",
      "Epoch : 32 | Avg. train batch loss = 0.1076 | Avg. val batch loss = 0.1584\n",
      "\n",
      "Epoch : 33 | Avg. train batch loss = 0.1051 | Avg. val batch loss = 0.1568\n",
      "\n",
      "Epoch : 34 | Avg. train batch loss = 0.1035 | Avg. val batch loss = 0.1531\n",
      "\n",
      "Epoch : 35 | Avg. train batch loss = 0.1008 | Avg. val batch loss = 0.1568\n",
      "\n",
      "Epoch : 36 | Avg. train batch loss = 0.0987 | Avg. val batch loss = 0.1538\n",
      "\n",
      "Epoch : 37 | Avg. train batch loss = 0.0960 | Avg. val batch loss = 0.1551\n",
      "\n",
      "Epoch : 38 | Avg. train batch loss = 0.0940 | Avg. val batch loss = 0.1564\n",
      "\n",
      "Epoch : 39 | Avg. train batch loss = 0.0922 | Avg. val batch loss = 0.1584\n",
      "\n",
      "Epoch : 40 | Avg. train batch loss = 0.0904 | Avg. val batch loss = 0.1515\n",
      "\n",
      "Epoch : 41 | Avg. train batch loss = 0.0889 | Avg. val batch loss = 0.1530\n",
      "\n",
      "Epoch : 42 | Avg. train batch loss = 0.0870 | Avg. val batch loss = 0.1496\n",
      "\n",
      "Epoch : 43 | Avg. train batch loss = 0.0862 | Avg. val batch loss = 0.1549\n",
      "\n",
      "Epoch : 44 | Avg. train batch loss = 0.0831 | Avg. val batch loss = 0.1486\n",
      "\n",
      "Epoch : 45 | Avg. train batch loss = 0.0835 | Avg. val batch loss = 0.1533\n",
      "\n",
      "Epoch : 46 | Avg. train batch loss = 0.0805 | Avg. val batch loss = 0.1535\n",
      "\n",
      "Epoch : 47 | Avg. train batch loss = 0.0784 | Avg. val batch loss = 0.1546\n",
      "\n",
      "Epoch : 48 | Avg. train batch loss = 0.0772 | Avg. val batch loss = 0.1531\n",
      "\n",
      "Epoch : 49 | Avg. train batch loss = 0.0766 | Avg. val batch loss = 0.1526\n",
      "\n",
      "Epoch : 50 | Avg. train batch loss = 0.0738 | Avg. val batch loss = 0.1538\n",
      "\n",
      "Epoch : 51 | Avg. train batch loss = 0.0736 | Avg. val batch loss = 0.1546\n",
      "\n",
      "Epoch : 52 | Avg. train batch loss = 0.0716 | Avg. val batch loss = 0.1517\n",
      "\n",
      "Epoch : 53 | Avg. train batch loss = 0.0698 | Avg. val batch loss = 0.1494\n",
      "\n",
      "Epoch : 54 | Avg. train batch loss = 0.0691 | Avg. val batch loss = 0.1471\n",
      "\n",
      "Epoch : 55 | Avg. train batch loss = 0.0681 | Avg. val batch loss = 0.1477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(data_loaders, model, optimizer, epochs, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'bpr.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
